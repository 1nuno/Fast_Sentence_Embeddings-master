{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute & Compare Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from gensim.models import KeyedVectors\n",
    "from fse.models import Sentence2Vec\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "from wordfreq import get_frequency_dict\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a pre-trained embedding that is compatible with any of the Gensim models and load it. For example, the original Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.35 ms\n"
     ]
    }
   ],
   "source": [
    "# Load if not on disk\n",
    "p = pathlib.Path(\"data/GoogleNews-vectors-negative300.bin\")\n",
    "if not p.exists():\n",
    "    !wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz -P data/\n",
    "    !gunzip data/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 09:05:30,571 : INFO : loading projection weights from data/GoogleNews-vectors-negative300.bin\n",
      "/Users/oliverborchers/anaconda3/envs/gsdev/lib/python3.7/site-packages/smart_open-1.8.4-py3.7.egg/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-06-17 09:06:23,187 : INFO : loaded (3000000, 300) matrix from data/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained word2vec model\n",
    "model = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 86 ms\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/reddit/\"\n",
    "\n",
    "p = pathlib.Path(data_path)\n",
    "\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(\"Directory does not exist.\")\n",
    "\n",
    "file_list=[]\n",
    "for f in p.iterdir():\n",
    "    if f.is_file():\n",
    "        file_list.append(f)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "        \n",
    "for i, f in enumerate(file_list):\n",
    "    df_tmp = pd.read_csv(f)\n",
    "    df_tmp[\"label\"] = i\n",
    "    df_tmp = df_tmp[[\"title\", \"label\"]]\n",
    "    data = pd.concat([data, df_tmp])\n",
    "    \n",
    "min_data = np.min(np.unique(data.label.values, return_counts=True)[1])\n",
    "labels = np.unique(data.label.values)\n",
    "\n",
    "data_balanced = pd.DataFrame()\n",
    "\n",
    "for i in labels:\n",
    "    data_balanced = pd.concat([data_balanced, data[data[\"label\"] == i].sample(n=min_data, random_state=42)])\n",
    "    \n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "y = np.array(data_balanced.label.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 54.6 ms\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(sentence):\n",
    "    return [sub(\"[^a-zA-Z]\", \"\", w.lower()) for w in sentence.split()] \n",
    "\n",
    "data_balanced[\"title_processed\"] = (data_balanced['title'].apply(normalize_text))\n",
    "\n",
    "corpus = data_balanced[\"title_processed\"].values.tolist()\n",
    "labels = data_balanced.label.values.tolist()\n",
    "\n",
    "corpus = [[w for w in s if w in model.vocab] for s in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2460\n",
      "time: 582 µs\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45.6 ms\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_bow = count_vect.fit_transform([\" \".join(s) for s in corpus])\n",
    "x_tfidf = TfidfTransformer(use_idf=True).fit_transform(x_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 09:08:50,392 : INFO : pre-computing SIF weights\n",
      "2019-06-17 09:08:50,394 : INFO : no frequency mode: using wordfreq for estimation (lang=en)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "cbow_model = Sentence2Vec(model, alpha=0, components=0, no_frequency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 09:08:52,455 : INFO : estimated required memory for 2460 sentences and 300 dimensions: 2 MB (0 GB)\n",
      "2019-06-17 09:08:52,520 : INFO : finished computing sentence embeddings of 2451 effective sentences with 24746 effective words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 66.4 ms\n"
     ]
    }
   ],
   "source": [
    "x_cbow = cbow_model.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 09:08:52,528 : INFO : pre-computing SIF weights\n",
      "2019-06-17 09:08:52,530 : INFO : no frequency mode: using wordfreq for estimation (lang=en)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "sif_model = Sentence2Vec(model, alpha=1e-3, components=1, no_frequency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 09:08:56,390 : INFO : estimated required memory for 2460 sentences and 300 dimensions: 2 MB (0 GB)\n",
      "2019-06-17 09:08:56,422 : INFO : finished computing sentence embeddings of 2451 effective sentences with 24746 effective words\n",
      "2019-06-17 09:08:56,422 : INFO : computing 1 principal components\n",
      "2019-06-17 09:08:56,453 : INFO : removing 1 principal components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 67.8 ms\n"
     ]
    }
   ],
   "source": [
    "x_sif = sif_model.train(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparision for timing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.13 ms\n"
     ]
    }
   ],
   "source": [
    "from fse.exp.sif_variants import sif_embeddings_1\n",
    "logging.disable(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983 ms ± 27.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "time: 7.95 s\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# This function does not remove the principal component\n",
    "sif_embeddings_1(corpus, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.1 ms ± 94.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cbow_model.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 560 µs\n"
     ]
    }
   ],
   "source": [
    "logging.disable(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 484 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "\n",
    "mds = dict()\n",
    "\n",
    "mds[\"BOW\"] = x_bow\n",
    "mds[\"TFIDF\"] = x_tfidf\n",
    "mds[\"CBOW\"] = x_cbow\n",
    "mds[\"SIF\"] = x_sif\n",
    "\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "\n",
    "p = pathlib.Path(\"excel\")\n",
    "p.mkdir(exist_ok=True)\n",
    "\n",
    "with pd.ExcelWriter(\"excel/pcomp_\"+date_time+\".xlsx\") as writer:\n",
    "    for k in mds.keys():\n",
    "        x_train, x_test, y_train, y_test = train_test_split(mds[k], labels, test_size=0.5, random_state=42)\n",
    "        clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        df = pd.DataFrame(metrics.classification_report(y_test, y_pred, output_dict=True)).T\n",
    "        df.to_excel(writer, sheet_name=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STS Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the STS Benchmark Dataset from: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark.\n",
    "Some of the lines may be skipped due to errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1041: expected 7 fields, saw 8\\nSkipping line 1065: expected 7 fields, saw 8\\nSkipping line 1082: expected 7 fields, saw 8\\nSkipping line 1136: expected 7 fields, saw 8\\nSkipping line 1149: expected 7 fields, saw 8\\nSkipping line 1449: expected 7 fields, saw 9\\nSkipping line 1450: expected 7 fields, saw 9\\nSkipping line 1451: expected 7 fields, saw 9\\nSkipping line 1452: expected 7 fields, saw 9\\nSkipping line 1453: expected 7 fields, saw 9\\nSkipping line 1454: expected 7 fields, saw 9\\nSkipping line 1455: expected 7 fields, saw 9\\nSkipping line 1456: expected 7 fields, saw 9\\nSkipping line 1457: expected 7 fields, saw 9\\nSkipping line 1458: expected 7 fields, saw 9\\nSkipping line 1459: expected 7 fields, saw 9\\nSkipping line 1460: expected 7 fields, saw 9\\nSkipping line 1461: expected 7 fields, saw 9\\nSkipping line 1462: expected 7 fields, saw 9\\nSkipping line 1463: expected 7 fields, saw 9\\nSkipping line 1464: expected 7 fields, saw 9\\nSkipping line 1465: expected 7 fields, saw 9\\nSkipping line 1466: expected 7 fields, saw 9\\nSkipping line 1467: expected 7 fields, saw 9\\nSkipping line 1468: expected 7 fields, saw 9\\nSkipping line 1469: expected 7 fields, saw 9\\nSkipping line 1470: expected 7 fields, saw 9\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 364 ms\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/stsbenchmark/sts-dev.csv\"\n",
    "\n",
    "p = pathlib.Path(file_path)\n",
    "\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(\"Directory does not exist.\")\n",
    "\n",
    "sts_data = pd.read_csv(file_path, sep=\"\\t\", error_bad_lines=False, header=None)\n",
    "sts_data = sts_data[[5,6,4]]\n",
    "sts_data.columns = [\"A\", \"B\", \"sim\"]\n",
    "sts_data.dropna(inplace=True)\n",
    "sts_data.A = (sts_data.A.apply(normalize_text))\n",
    "sts_data.B = (sts_data.B.apply(normalize_text))\n",
    "\n",
    "sents_a = sts_data.A.values.tolist()\n",
    "sents_b = sts_data.B.values.tolist()\n",
    "assert len(sents_a) == len(sents_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 09:09:08,994 : INFO : estimated required memory for 1441 sentences and 300 dimensions: 1 MB (0 GB)\n",
      "2019-06-17 09:09:09,022 : INFO : finished computing sentence embeddings of 1441 effective sentences with 13876 effective words\n",
      "2019-06-17 09:09:09,023 : INFO : estimated required memory for 1441 sentences and 300 dimensions: 1 MB (0 GB)\n",
      "2019-06-17 09:09:09,045 : INFO : finished computing sentence embeddings of 1441 effective sentences with 13681 effective words\n",
      "2019-06-17 09:09:09,046 : INFO : computing L2-norms of sentence embeddings\n",
      "2019-06-17 09:09:09,062 : INFO : computing L2-norms of sentence embeddings\n",
      "2019-06-17 09:09:09,077 : INFO : estimated required memory for 1441 sentences and 300 dimensions: 1 MB (0 GB)\n",
      "2019-06-17 09:09:09,092 : INFO : finished computing sentence embeddings of 1441 effective sentences with 13876 effective words\n",
      "2019-06-17 09:09:09,093 : INFO : computing 1 principal components\n",
      "2019-06-17 09:09:09,101 : INFO : removing 1 principal components\n",
      "2019-06-17 09:09:09,104 : INFO : estimated required memory for 1441 sentences and 300 dimensions: 1 MB (0 GB)\n",
      "2019-06-17 09:09:09,122 : INFO : finished computing sentence embeddings of 1441 effective sentences with 13681 effective words\n",
      "2019-06-17 09:09:09,123 : INFO : computing 1 principal components\n",
      "2019-06-17 09:09:09,130 : INFO : removing 1 principal components\n",
      "2019-06-17 09:09:09,133 : INFO : computing L2-norms of sentence embeddings\n",
      "2019-06-17 09:09:09,152 : INFO : computing L2-norms of sentence embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "cbow_vecs_a = cbow_model.train(sents_a)\n",
    "cbow_vecs_b = cbow_model.train(sents_b)\n",
    "cbow_model.normalize(cbow_vecs_a)\n",
    "cbow_model.normalize(cbow_vecs_b)\n",
    "\n",
    "sif_vecs_a = sif_model.train(sents_a)\n",
    "sif_vecs_b = sif_model.train(sents_b)\n",
    "sif_model.normalize(sif_vecs_a)\n",
    "sif_model.normalize(sif_vecs_b)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results[\"STS\"] = sts_data.sim\n",
    "\n",
    "def pearson_correlation(mat_a, mat_b):\n",
    "    assert mat_a.shape == mat_b.shape\n",
    "    results = []\n",
    "    for i in range(len(mat_a)):\n",
    "        results.append(mat_a[i].dot(mat_b[i]))\n",
    "    return results\n",
    "\n",
    "results[\"CBOW\"] = pearson_correlation(cbow_vecs_a, cbow_vecs_b)\n",
    "results[\"SIF\"] = pearson_correlation(sif_vecs_a, sif_vecs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.2 ms\n"
     ]
    }
   ],
   "source": [
    "results = results.corr()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "results.to_excel(\"excel/STScomp_\"+date_time+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STS</th>\n",
       "      <th>CBOW</th>\n",
       "      <th>SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722721</td>\n",
       "      <td>0.775961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBOW</th>\n",
       "      <td>0.722721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIF</th>\n",
       "      <td>0.775961</td>\n",
       "      <td>0.918188</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           STS      CBOW       SIF\n",
       "STS   1.000000  0.722721  0.775961\n",
       "CBOW  0.722721  1.000000  0.918188\n",
       "SIF   0.775961  0.918188  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.1 ms\n"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.42 ms\n"
     ]
    }
   ],
   "source": [
    "def load_sts(file_path):\n",
    "    p = pathlib.Path(file_path)\n",
    "\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(\"Directory does not exist.\")\n",
    "        \n",
    "    sts_data = pd.read_csv(file_path, sep=\"\\t\", error_bad_lines=False, header=None)\n",
    "    sts_data = sts_data[[5,6,4]]\n",
    "    sts_data.columns = [\"A\", \"B\", \"sim\"]\n",
    "    sts_data.dropna(inplace=True)\n",
    "    sts_data.A = (sts_data.A.apply(normalize_text))\n",
    "    sts_data.B = (sts_data.B.apply(normalize_text))\n",
    "    \n",
    "    sents_a = sts_data.A.values.tolist()\n",
    "    sents_b = sts_data.B.values.tolist()\n",
    "    assert len(sents_a) == len(sents_b)\n",
    "    \n",
    "    sims = sts_data.sim.values.tolist()\n",
    "    sims /= np.max(sims)\n",
    "    return sents_a, sents_b, sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2508: expected 7 fields, saw 8\\nSkipping line 2649: expected 7 fields, saw 8\\nSkipping line 2726: expected 7 fields, saw 8\\nSkipping line 3070: expected 7 fields, saw 8\\nSkipping line 3392: expected 7 fields, saw 8\\nSkipping line 5515: expected 7 fields, saw 9\\nSkipping line 5516: expected 7 fields, saw 9\\nSkipping line 5517: expected 7 fields, saw 9\\nSkipping line 5518: expected 7 fields, saw 9\\nSkipping line 5519: expected 7 fields, saw 9\\nSkipping line 5520: expected 7 fields, saw 9\\nSkipping line 5521: expected 7 fields, saw 9\\nSkipping line 5522: expected 7 fields, saw 9\\nSkipping line 5523: expected 7 fields, saw 9\\nSkipping line 5524: expected 7 fields, saw 9\\nSkipping line 5525: expected 7 fields, saw 9\\nSkipping line 5526: expected 7 fields, saw 9\\nSkipping line 5527: expected 7 fields, saw 9\\nSkipping line 5528: expected 7 fields, saw 9\\nSkipping line 5529: expected 7 fields, saw 9\\nSkipping line 5530: expected 7 fields, saw 9\\nSkipping line 5531: expected 7 fields, saw 9\\nSkipping line 5532: expected 7 fields, saw 9\\nSkipping line 5533: expected 7 fields, saw 9\\nSkipping line 5534: expected 7 fields, saw 9\\nSkipping line 5535: expected 7 fields, saw 9\\nSkipping line 5536: expected 7 fields, saw 9\\nSkipping line 5537: expected 7 fields, saw 9\\nSkipping line 5538: expected 7 fields, saw 9\\nSkipping line 5539: expected 7 fields, saw 9\\nSkipping line 5540: expected 7 fields, saw 9\\nSkipping line 5541: expected 7 fields, saw 9\\nSkipping line 5542: expected 7 fields, saw 9\\nSkipping line 5543: expected 7 fields, saw 9\\nSkipping line 5544: expected 7 fields, saw 9\\nSkipping line 5545: expected 7 fields, saw 9\\nSkipping line 5546: expected 7 fields, saw 9\\nSkipping line 5547: expected 7 fields, saw 9\\nSkipping line 5548: expected 7 fields, saw 9\\nSkipping line 5549: expected 7 fields, saw 9\\nSkipping line 5550: expected 7 fields, saw 9\\nSkipping line 5551: expected 7 fields, saw 9\\nSkipping line 5552: expected 7 fields, saw 9\\nSkipping line 5553: expected 7 fields, saw 9\\nSkipping line 5554: expected 7 fields, saw 9\\nSkipping line 5555: expected 7 fields, saw 9\\nSkipping line 5556: expected 7 fields, saw 9\\nSkipping line 5557: expected 7 fields, saw 9\\nSkipping line 5558: expected 7 fields, saw 9\\nSkipping line 5559: expected 7 fields, saw 9\\nSkipping line 5560: expected 7 fields, saw 9\\nSkipping line 5561: expected 7 fields, saw 9\\nSkipping line 5562: expected 7 fields, saw 9\\nSkipping line 5563: expected 7 fields, saw 9\\nSkipping line 5564: expected 7 fields, saw 9\\nSkipping line 5565: expected 7 fields, saw 9\\nSkipping line 5566: expected 7 fields, saw 9\\nSkipping line 5567: expected 7 fields, saw 9\\nSkipping line 5568: expected 7 fields, saw 9\\nSkipping line 5569: expected 7 fields, saw 9\\nSkipping line 5570: expected 7 fields, saw 9\\nSkipping line 5571: expected 7 fields, saw 9\\nSkipping line 5572: expected 7 fields, saw 9\\nSkipping line 5573: expected 7 fields, saw 9\\nSkipping line 5574: expected 7 fields, saw 9\\nSkipping line 5575: expected 7 fields, saw 9\\nSkipping line 5576: expected 7 fields, saw 9\\nSkipping line 5577: expected 7 fields, saw 9\\nSkipping line 5578: expected 7 fields, saw 9\\nSkipping line 5579: expected 7 fields, saw 9\\nSkipping line 5580: expected 7 fields, saw 9\\nSkipping line 5581: expected 7 fields, saw 9\\nSkipping line 5582: expected 7 fields, saw 9\\nSkipping line 5583: expected 7 fields, saw 9\\nSkipping line 5584: expected 7 fields, saw 9\\nSkipping line 5585: expected 7 fields, saw 9\\nSkipping line 5586: expected 7 fields, saw 9\\nSkipping line 5587: expected 7 fields, saw 9\\nSkipping line 5588: expected 7 fields, saw 9\\nSkipping line 5589: expected 7 fields, saw 9\\nSkipping line 5590: expected 7 fields, saw 9\\nSkipping line 5591: expected 7 fields, saw 9\\nSkipping line 5592: expected 7 fields, saw 9\\nSkipping line 5593: expected 7 fields, saw 9\\nSkipping line 5594: expected 7 fields, saw 9\\nSkipping line 5595: expected 7 fields, saw 9\\nSkipping line 5596: expected 7 fields, saw 9\\nSkipping line 5597: expected 7 fields, saw 9\\nSkipping line 5598: expected 7 fields, saw 9\\nSkipping line 5599: expected 7 fields, saw 9\\nSkipping line 5600: expected 7 fields, saw 9\\nSkipping line 5601: expected 7 fields, saw 9\\nSkipping line 5602: expected 7 fields, saw 9\\nSkipping line 5603: expected 7 fields, saw 9\\nSkipping line 5604: expected 7 fields, saw 9\\nSkipping line 5605: expected 7 fields, saw 9\\nSkipping line 5606: expected 7 fields, saw 9\\nSkipping line 5607: expected 7 fields, saw 9\\nSkipping line 5608: expected 7 fields, saw 9\\nSkipping line 5609: expected 7 fields, saw 9\\nSkipping line 5610: expected 7 fields, saw 9\\nSkipping line 5611: expected 7 fields, saw 9\\nSkipping line 5612: expected 7 fields, saw 9\\nSkipping line 5613: expected 7 fields, saw 9\\nSkipping line 5614: expected 7 fields, saw 9\\nSkipping line 5615: expected 7 fields, saw 9\\nSkipping line 5616: expected 7 fields, saw 9\\nSkipping line 5617: expected 7 fields, saw 9\\nSkipping line 5618: expected 7 fields, saw 9\\nSkipping line 5619: expected 7 fields, saw 9\\nSkipping line 5620: expected 7 fields, saw 9\\nSkipping line 5621: expected 7 fields, saw 9\\nSkipping line 5622: expected 7 fields, saw 9\\nSkipping line 5623: expected 7 fields, saw 9\\nSkipping line 5624: expected 7 fields, saw 9\\nSkipping line 5625: expected 7 fields, saw 9\\nSkipping line 5626: expected 7 fields, saw 9\\nSkipping line 5627: expected 7 fields, saw 9\\nSkipping line 5628: expected 7 fields, saw 9\\nSkipping line 5629: expected 7 fields, saw 9\\nSkipping line 5630: expected 7 fields, saw 9\\nSkipping line 5631: expected 7 fields, saw 9\\nSkipping line 5632: expected 7 fields, saw 9\\nSkipping line 5633: expected 7 fields, saw 9\\nSkipping line 5634: expected 7 fields, saw 9\\nSkipping line 5635: expected 7 fields, saw 9\\nSkipping line 5636: expected 7 fields, saw 9\\nSkipping line 5637: expected 7 fields, saw 9\\nSkipping line 5638: expected 7 fields, saw 9\\nSkipping line 5639: expected 7 fields, saw 9\\nSkipping line 5640: expected 7 fields, saw 9\\nSkipping line 5641: expected 7 fields, saw 9\\nSkipping line 5642: expected 7 fields, saw 9\\nSkipping line 5643: expected 7 fields, saw 9\\nSkipping line 5644: expected 7 fields, saw 9\\nSkipping line 5645: expected 7 fields, saw 9\\nSkipping line 5646: expected 7 fields, saw 9\\nSkipping line 5647: expected 7 fields, saw 9\\nSkipping line 5648: expected 7 fields, saw 9\\nSkipping line 5649: expected 7 fields, saw 9\\nSkipping line 5650: expected 7 fields, saw 9\\nSkipping line 5651: expected 7 fields, saw 9\\nSkipping line 5652: expected 7 fields, saw 9\\nSkipping line 5653: expected 7 fields, saw 9\\nSkipping line 5654: expected 7 fields, saw 9\\nSkipping line 5655: expected 7 fields, saw 9\\nSkipping line 5656: expected 7 fields, saw 9\\nSkipping line 5657: expected 7 fields, saw 9\\nSkipping line 5658: expected 7 fields, saw 9\\nSkipping line 5659: expected 7 fields, saw 9\\nSkipping line 5660: expected 7 fields, saw 9\\nSkipping line 5661: expected 7 fields, saw 9\\nSkipping line 5662: expected 7 fields, saw 9\\nSkipping line 5663: expected 7 fields, saw 9\\nSkipping line 5664: expected 7 fields, saw 9\\nSkipping line 5665: expected 7 fields, saw 9\\nSkipping line 5666: expected 7 fields, saw 9\\nSkipping line 5667: expected 7 fields, saw 9\\nSkipping line 5668: expected 7 fields, saw 9\\nSkipping line 5669: expected 7 fields, saw 9\\nSkipping line 5670: expected 7 fields, saw 9\\nSkipping line 5671: expected 7 fields, saw 9\\nSkipping line 5672: expected 7 fields, saw 9\\nSkipping line 5673: expected 7 fields, saw 9\\nSkipping line 5674: expected 7 fields, saw 9\\nSkipping line 5675: expected 7 fields, saw 9\\nSkipping line 5676: expected 7 fields, saw 9\\nSkipping line 5677: expected 7 fields, saw 9\\nSkipping line 5678: expected 7 fields, saw 9\\nSkipping line 5679: expected 7 fields, saw 9\\nSkipping line 5680: expected 7 fields, saw 9\\nSkipping line 5681: expected 7 fields, saw 9\\nSkipping line 5682: expected 7 fields, saw 9\\nSkipping line 5683: expected 7 fields, saw 9\\nSkipping line 5684: expected 7 fields, saw 9\\nSkipping line 5685: expected 7 fields, saw 9\\nSkipping line 5686: expected 7 fields, saw 9\\nSkipping line 5687: expected 7 fields, saw 9\\nSkipping line 5688: expected 7 fields, saw 9\\nSkipping line 5689: expected 7 fields, saw 9\\nSkipping line 5690: expected 7 fields, saw 9\\nSkipping line 5691: expected 7 fields, saw 9\\nSkipping line 5692: expected 7 fields, saw 9\\nSkipping line 5693: expected 7 fields, saw 9\\nSkipping line 5694: expected 7 fields, saw 9\\nSkipping line 5695: expected 7 fields, saw 9\\nSkipping line 5696: expected 7 fields, saw 9\\nSkipping line 5697: expected 7 fields, saw 9\\nSkipping line 5698: expected 7 fields, saw 9\\nSkipping line 5699: expected 7 fields, saw 9\\nSkipping line 5700: expected 7 fields, saw 9\\nSkipping line 5701: expected 7 fields, saw 9\\nSkipping line 5702: expected 7 fields, saw 9\\nSkipping line 5703: expected 7 fields, saw 9\\nSkipping line 5704: expected 7 fields, saw 9\\nSkipping line 5705: expected 7 fields, saw 9\\nSkipping line 5706: expected 7 fields, saw 9\\nSkipping line 5707: expected 7 fields, saw 9\\nSkipping line 5708: expected 7 fields, saw 9\\nSkipping line 5709: expected 7 fields, saw 9\\nSkipping line 5710: expected 7 fields, saw 9\\nSkipping line 5711: expected 7 fields, saw 9\\n'\n",
      "b'Skipping line 1041: expected 7 fields, saw 8\\nSkipping line 1065: expected 7 fields, saw 8\\nSkipping line 1082: expected 7 fields, saw 8\\nSkipping line 1136: expected 7 fields, saw 8\\nSkipping line 1149: expected 7 fields, saw 8\\nSkipping line 1449: expected 7 fields, saw 9\\nSkipping line 1450: expected 7 fields, saw 9\\nSkipping line 1451: expected 7 fields, saw 9\\nSkipping line 1452: expected 7 fields, saw 9\\nSkipping line 1453: expected 7 fields, saw 9\\nSkipping line 1454: expected 7 fields, saw 9\\nSkipping line 1455: expected 7 fields, saw 9\\nSkipping line 1456: expected 7 fields, saw 9\\nSkipping line 1457: expected 7 fields, saw 9\\nSkipping line 1458: expected 7 fields, saw 9\\nSkipping line 1459: expected 7 fields, saw 9\\nSkipping line 1460: expected 7 fields, saw 9\\nSkipping line 1461: expected 7 fields, saw 9\\nSkipping line 1462: expected 7 fields, saw 9\\nSkipping line 1463: expected 7 fields, saw 9\\nSkipping line 1464: expected 7 fields, saw 9\\nSkipping line 1465: expected 7 fields, saw 9\\nSkipping line 1466: expected 7 fields, saw 9\\nSkipping line 1467: expected 7 fields, saw 9\\nSkipping line 1468: expected 7 fields, saw 9\\nSkipping line 1469: expected 7 fields, saw 9\\nSkipping line 1470: expected 7 fields, saw 9\\n'\n",
      "b'Skipping line 626: expected 7 fields, saw 9\\nSkipping line 627: expected 7 fields, saw 9\\nSkipping line 628: expected 7 fields, saw 9\\nSkipping line 629: expected 7 fields, saw 9\\nSkipping line 630: expected 7 fields, saw 9\\nSkipping line 631: expected 7 fields, saw 9\\nSkipping line 632: expected 7 fields, saw 9\\nSkipping line 633: expected 7 fields, saw 9\\nSkipping line 634: expected 7 fields, saw 9\\nSkipping line 635: expected 7 fields, saw 9\\nSkipping line 636: expected 7 fields, saw 9\\nSkipping line 637: expected 7 fields, saw 9\\nSkipping line 638: expected 7 fields, saw 9\\nSkipping line 639: expected 7 fields, saw 9\\nSkipping line 640: expected 7 fields, saw 9\\nSkipping line 641: expected 7 fields, saw 9\\nSkipping line 642: expected 7 fields, saw 9\\nSkipping line 643: expected 7 fields, saw 9\\nSkipping line 644: expected 7 fields, saw 9\\nSkipping line 645: expected 7 fields, saw 9\\nSkipping line 646: expected 7 fields, saw 9\\nSkipping line 647: expected 7 fields, saw 9\\nSkipping line 648: expected 7 fields, saw 9\\nSkipping line 649: expected 7 fields, saw 9\\nSkipping line 650: expected 7 fields, saw 9\\nSkipping line 651: expected 7 fields, saw 9\\nSkipping line 652: expected 7 fields, saw 9\\nSkipping line 653: expected 7 fields, saw 9\\nSkipping line 654: expected 7 fields, saw 9\\nSkipping line 655: expected 7 fields, saw 9\\nSkipping line 656: expected 7 fields, saw 9\\nSkipping line 657: expected 7 fields, saw 9\\nSkipping line 658: expected 7 fields, saw 9\\nSkipping line 659: expected 7 fields, saw 9\\nSkipping line 660: expected 7 fields, saw 9\\nSkipping line 661: expected 7 fields, saw 9\\nSkipping line 662: expected 7 fields, saw 9\\nSkipping line 663: expected 7 fields, saw 9\\nSkipping line 664: expected 7 fields, saw 9\\nSkipping line 665: expected 7 fields, saw 9\\nSkipping line 666: expected 7 fields, saw 9\\nSkipping line 667: expected 7 fields, saw 9\\nSkipping line 668: expected 7 fields, saw 9\\nSkipping line 669: expected 7 fields, saw 9\\nSkipping line 670: expected 7 fields, saw 9\\nSkipping line 671: expected 7 fields, saw 9\\nSkipping line 672: expected 7 fields, saw 9\\nSkipping line 673: expected 7 fields, saw 9\\nSkipping line 674: expected 7 fields, saw 9\\nSkipping line 675: expected 7 fields, saw 9\\nSkipping line 676: expected 7 fields, saw 9\\nSkipping line 677: expected 7 fields, saw 9\\nSkipping line 678: expected 7 fields, saw 9\\nSkipping line 679: expected 7 fields, saw 9\\nSkipping line 680: expected 7 fields, saw 9\\nSkipping line 681: expected 7 fields, saw 9\\nSkipping line 682: expected 7 fields, saw 9\\nSkipping line 683: expected 7 fields, saw 9\\nSkipping line 684: expected 7 fields, saw 9\\nSkipping line 685: expected 7 fields, saw 9\\nSkipping line 686: expected 7 fields, saw 9\\nSkipping line 687: expected 7 fields, saw 9\\nSkipping line 688: expected 7 fields, saw 9\\nSkipping line 689: expected 7 fields, saw 9\\nSkipping line 690: expected 7 fields, saw 9\\nSkipping line 691: expected 7 fields, saw 9\\nSkipping line 692: expected 7 fields, saw 9\\nSkipping line 693: expected 7 fields, saw 9\\nSkipping line 694: expected 7 fields, saw 9\\nSkipping line 695: expected 7 fields, saw 9\\nSkipping line 696: expected 7 fields, saw 9\\nSkipping line 697: expected 7 fields, saw 9\\nSkipping line 698: expected 7 fields, saw 9\\nSkipping line 699: expected 7 fields, saw 9\\nSkipping line 700: expected 7 fields, saw 9\\nSkipping line 701: expected 7 fields, saw 9\\nSkipping line 702: expected 7 fields, saw 9\\nSkipping line 703: expected 7 fields, saw 9\\nSkipping line 704: expected 7 fields, saw 9\\nSkipping line 705: expected 7 fields, saw 9\\nSkipping line 706: expected 7 fields, saw 9\\nSkipping line 707: expected 7 fields, saw 9\\nSkipping line 708: expected 7 fields, saw 9\\nSkipping line 709: expected 7 fields, saw 9\\nSkipping line 710: expected 7 fields, saw 9\\nSkipping line 711: expected 7 fields, saw 9\\nSkipping line 712: expected 7 fields, saw 9\\nSkipping line 713: expected 7 fields, saw 9\\nSkipping line 714: expected 7 fields, saw 9\\nSkipping line 715: expected 7 fields, saw 9\\nSkipping line 716: expected 7 fields, saw 9\\nSkipping line 717: expected 7 fields, saw 9\\nSkipping line 718: expected 7 fields, saw 9\\nSkipping line 719: expected 7 fields, saw 9\\nSkipping line 720: expected 7 fields, saw 9\\nSkipping line 721: expected 7 fields, saw 9\\nSkipping line 722: expected 7 fields, saw 9\\nSkipping line 723: expected 7 fields, saw 9\\nSkipping line 724: expected 7 fields, saw 9\\nSkipping line 725: expected 7 fields, saw 9\\nSkipping line 726: expected 7 fields, saw 9\\nSkipping line 727: expected 7 fields, saw 9\\nSkipping line 728: expected 7 fields, saw 9\\nSkipping line 729: expected 7 fields, saw 9\\nSkipping line 730: expected 7 fields, saw 9\\nSkipping line 731: expected 7 fields, saw 9\\nSkipping line 732: expected 7 fields, saw 9\\nSkipping line 733: expected 7 fields, saw 9\\nSkipping line 734: expected 7 fields, saw 9\\nSkipping line 735: expected 7 fields, saw 9\\nSkipping line 736: expected 7 fields, saw 9\\nSkipping line 737: expected 7 fields, saw 9\\nSkipping line 738: expected 7 fields, saw 9\\nSkipping line 739: expected 7 fields, saw 9\\nSkipping line 740: expected 7 fields, saw 9\\nSkipping line 741: expected 7 fields, saw 9\\nSkipping line 742: expected 7 fields, saw 9\\nSkipping line 743: expected 7 fields, saw 9\\nSkipping line 744: expected 7 fields, saw 9\\nSkipping line 745: expected 7 fields, saw 9\\nSkipping line 746: expected 7 fields, saw 9\\nSkipping line 747: expected 7 fields, saw 9\\nSkipping line 748: expected 7 fields, saw 9\\nSkipping line 749: expected 7 fields, saw 9\\nSkipping line 750: expected 7 fields, saw 9\\nSkipping line 751: expected 7 fields, saw 9\\nSkipping line 752: expected 7 fields, saw 9\\nSkipping line 753: expected 7 fields, saw 9\\nSkipping line 754: expected 7 fields, saw 9\\nSkipping line 755: expected 7 fields, saw 9\\nSkipping line 756: expected 7 fields, saw 9\\nSkipping line 757: expected 7 fields, saw 9\\nSkipping line 758: expected 7 fields, saw 9\\nSkipping line 759: expected 7 fields, saw 9\\nSkipping line 760: expected 7 fields, saw 9\\nSkipping line 761: expected 7 fields, saw 9\\nSkipping line 762: expected 7 fields, saw 9\\nSkipping line 763: expected 7 fields, saw 9\\nSkipping line 764: expected 7 fields, saw 9\\nSkipping line 765: expected 7 fields, saw 9\\nSkipping line 766: expected 7 fields, saw 9\\nSkipping line 767: expected 7 fields, saw 9\\nSkipping line 768: expected 7 fields, saw 9\\nSkipping line 769: expected 7 fields, saw 9\\nSkipping line 770: expected 7 fields, saw 9\\nSkipping line 771: expected 7 fields, saw 9\\nSkipping line 772: expected 7 fields, saw 9\\nSkipping line 773: expected 7 fields, saw 9\\nSkipping line 774: expected 7 fields, saw 9\\nSkipping line 775: expected 7 fields, saw 9\\nSkipping line 776: expected 7 fields, saw 9\\nSkipping line 777: expected 7 fields, saw 9\\nSkipping line 778: expected 7 fields, saw 9\\nSkipping line 779: expected 7 fields, saw 9\\nSkipping line 780: expected 7 fields, saw 9\\nSkipping line 781: expected 7 fields, saw 9\\nSkipping line 782: expected 7 fields, saw 9\\nSkipping line 783: expected 7 fields, saw 9\\nSkipping line 784: expected 7 fields, saw 9\\nSkipping line 785: expected 7 fields, saw 9\\nSkipping line 786: expected 7 fields, saw 9\\nSkipping line 787: expected 7 fields, saw 9\\nSkipping line 788: expected 7 fields, saw 9\\nSkipping line 789: expected 7 fields, saw 9\\nSkipping line 790: expected 7 fields, saw 9\\nSkipping line 791: expected 7 fields, saw 9\\nSkipping line 792: expected 7 fields, saw 9\\nSkipping line 793: expected 7 fields, saw 9\\nSkipping line 794: expected 7 fields, saw 9\\nSkipping line 795: expected 7 fields, saw 9\\nSkipping line 796: expected 7 fields, saw 9\\nSkipping line 797: expected 7 fields, saw 9\\nSkipping line 798: expected 7 fields, saw 9\\nSkipping line 799: expected 7 fields, saw 9\\nSkipping line 800: expected 7 fields, saw 9\\nSkipping line 801: expected 7 fields, saw 9\\nSkipping line 802: expected 7 fields, saw 9\\nSkipping line 803: expected 7 fields, saw 9\\nSkipping line 804: expected 7 fields, saw 9\\nSkipping line 805: expected 7 fields, saw 9\\nSkipping line 806: expected 7 fields, saw 9\\nSkipping line 807: expected 7 fields, saw 9\\nSkipping line 808: expected 7 fields, saw 9\\nSkipping line 809: expected 7 fields, saw 9\\nSkipping line 810: expected 7 fields, saw 9\\nSkipping line 811: expected 7 fields, saw 9\\nSkipping line 812: expected 7 fields, saw 9\\nSkipping line 813: expected 7 fields, saw 9\\nSkipping line 814: expected 7 fields, saw 9\\nSkipping line 815: expected 7 fields, saw 9\\nSkipping line 816: expected 7 fields, saw 9\\nSkipping line 817: expected 7 fields, saw 9\\nSkipping line 818: expected 7 fields, saw 9\\nSkipping line 819: expected 7 fields, saw 9\\nSkipping line 820: expected 7 fields, saw 9\\nSkipping line 821: expected 7 fields, saw 9\\nSkipping line 822: expected 7 fields, saw 9\\nSkipping line 823: expected 7 fields, saw 9\\nSkipping line 824: expected 7 fields, saw 9\\nSkipping line 825: expected 7 fields, saw 9\\nSkipping line 826: expected 7 fields, saw 9\\nSkipping line 827: expected 7 fields, saw 9\\nSkipping line 828: expected 7 fields, saw 9\\nSkipping line 829: expected 7 fields, saw 9\\nSkipping line 830: expected 7 fields, saw 9\\nSkipping line 831: expected 7 fields, saw 9\\nSkipping line 832: expected 7 fields, saw 9\\nSkipping line 833: expected 7 fields, saw 9\\nSkipping line 834: expected 7 fields, saw 9\\nSkipping line 835: expected 7 fields, saw 9\\nSkipping line 836: expected 7 fields, saw 9\\nSkipping line 837: expected 7 fields, saw 9\\nSkipping line 838: expected 7 fields, saw 9\\nSkipping line 839: expected 7 fields, saw 9\\nSkipping line 840: expected 7 fields, saw 9\\nSkipping line 841: expected 7 fields, saw 9\\nSkipping line 842: expected 7 fields, saw 9\\nSkipping line 843: expected 7 fields, saw 9\\nSkipping line 844: expected 7 fields, saw 9\\nSkipping line 845: expected 7 fields, saw 9\\nSkipping line 846: expected 7 fields, saw 9\\nSkipping line 847: expected 7 fields, saw 9\\nSkipping line 848: expected 7 fields, saw 9\\nSkipping line 849: expected 7 fields, saw 9\\nSkipping line 850: expected 7 fields, saw 9\\nSkipping line 851: expected 7 fields, saw 9\\nSkipping line 852: expected 7 fields, saw 9\\nSkipping line 853: expected 7 fields, saw 9\\nSkipping line 854: expected 7 fields, saw 9\\nSkipping line 855: expected 7 fields, saw 9\\nSkipping line 856: expected 7 fields, saw 9\\nSkipping line 857: expected 7 fields, saw 9\\nSkipping line 858: expected 7 fields, saw 9\\nSkipping line 859: expected 7 fields, saw 9\\nSkipping line 860: expected 7 fields, saw 9\\nSkipping line 861: expected 7 fields, saw 9\\nSkipping line 862: expected 7 fields, saw 9\\nSkipping line 863: expected 7 fields, saw 9\\nSkipping line 864: expected 7 fields, saw 9\\nSkipping line 865: expected 7 fields, saw 9\\nSkipping line 866: expected 7 fields, saw 9\\nSkipping line 867: expected 7 fields, saw 9\\nSkipping line 868: expected 7 fields, saw 9\\nSkipping line 869: expected 7 fields, saw 9\\nSkipping line 870: expected 7 fields, saw 9\\nSkipping line 871: expected 7 fields, saw 9\\nSkipping line 872: expected 7 fields, saw 9\\nSkipping line 873: expected 7 fields, saw 9\\nSkipping line 874: expected 7 fields, saw 9\\nSkipping line 875: expected 7 fields, saw 9\\nSkipping line 876: expected 7 fields, saw 9\\nSkipping line 877: expected 7 fields, saw 9\\nSkipping line 878: expected 7 fields, saw 9\\nSkipping line 879: expected 7 fields, saw 9\\n'\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 1118",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-cbd6f522f594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/stsbenchmark/sts-train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/stsbenchmark/sts-dev.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/stsbenchmark/sts-test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-018492dcae34>\u001b[0m in \u001b[0;36mload_sts\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Directory does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msts_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msts_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msts_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msts_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gsdev/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gsdev/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gsdev/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gsdev/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 1118"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "train_a, train_b, y_train = load_sts(\"data/stsbenchmark/sts-train.csv\")\n",
    "val_a, val_b, y_val = load_sts(\"data/stsbenchmark/sts-dev.csv\")\n",
    "test_a, test_b, y_test = load_sts(\"data/stsbenchmark/sts-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0617 09:18:51.062963 4781397440 sentence2vec.py:239] pre-computing SIF weights\n",
      "I0617 09:18:51.064175 4781397440 sentence2vec.py:242] no frequency mode: using wordfreq for estimation (lang=en)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "cbow_model = Sentence2Vec(model, alpha=1e-3, components=4, no_frequency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.5 ms\n"
     ]
    }
   ],
   "source": [
    "def sqd(a,b):\n",
    "    # Elementwise squared difference\n",
    "    return np.power(a-b,2)\n",
    "\n",
    "def compute_diff_features(x1, x2, model):\n",
    "    x1_v = model.train(x1)\n",
    "    x2_v = model.train(x2)\n",
    "    \n",
    "    model.normalize(x1_v)\n",
    "    model.normalize(x2_v)\n",
    "    \n",
    "    output = np.zeros_like(x1_v)\n",
    "    \n",
    "    for i in range(len(x1_v)):\n",
    "        output[i] = sqd(x1_v[i],x2_v[i])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0617 09:18:55.110586 4781397440 sentence2vec.py:300] estimated required memory for 5506 sentences and 300 dimensions: 6 MB (0 GB)\n",
      "I0617 09:18:55.168913 4781397440 sentence2vec.py:365] finished computing sentence embeddings of 5506 effective sentences with 45980 effective words\n",
      "I0617 09:18:55.169651 4781397440 sentence2vec.py:181] computing 4 principal components\n",
      "I0617 09:18:55.199650 4781397440 sentence2vec.py:208] removing 4 principal components\n",
      "I0617 09:18:55.206314 4781397440 sentence2vec.py:300] estimated required memory for 5506 sentences and 300 dimensions: 6 MB (0 GB)\n",
      "I0617 09:18:55.269970 4781397440 sentence2vec.py:365] finished computing sentence embeddings of 5506 effective sentences with 45856 effective words\n",
      "I0617 09:18:55.270796 4781397440 sentence2vec.py:181] computing 4 principal components\n",
      "I0617 09:18:55.297655 4781397440 sentence2vec.py:208] removing 4 principal components\n",
      "I0617 09:18:55.304008 4781397440 sentence2vec.py:326] computing L2-norms of sentence embeddings\n",
      "I0617 09:18:55.386847 4781397440 sentence2vec.py:326] computing L2-norms of sentence embeddings\n",
      "I0617 09:18:55.522746 4781397440 sentence2vec.py:300] estimated required memory for 1441 sentences and 300 dimensions: 1 MB (0 GB)\n",
      "I0617 09:18:55.541131 4781397440 sentence2vec.py:365] finished computing sentence embeddings of 1441 effective sentences with 13876 effective words\n",
      "I0617 09:18:55.541846 4781397440 sentence2vec.py:181] computing 4 principal components\n",
      "I0617 09:18:55.551263 4781397440 sentence2vec.py:208] removing 4 principal components\n",
      "I0617 09:18:55.554329 4781397440 sentence2vec.py:300] estimated required memory for 1441 sentences and 300 dimensions: 1 MB (0 GB)\n",
      "I0617 09:18:55.576890 4781397440 sentence2vec.py:365] finished computing sentence embeddings of 1441 effective sentences with 13681 effective words\n",
      "I0617 09:18:55.577704 4781397440 sentence2vec.py:181] computing 4 principal components\n",
      "I0617 09:18:55.586091 4781397440 sentence2vec.py:208] removing 4 principal components\n",
      "I0617 09:18:55.589063 4781397440 sentence2vec.py:326] computing L2-norms of sentence embeddings\n",
      "I0617 09:18:55.612264 4781397440 sentence2vec.py:326] computing L2-norms of sentence embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 542 ms\n"
     ]
    }
   ],
   "source": [
    "x_train = compute_diff_features(train_a, train_b, cbow_model)\n",
    "x_val = compute_diff_features(val_a, val_b, cbow_model)\n",
    "#x_test = compute_diff_features(test_a, test_b, cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>sqd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqd</th>\n",
       "      <td>0.738595</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t       sqd\n",
       "t    1.000000  0.738595\n",
       "sqd  0.738595  1.000000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.7 ms\n"
     ]
    }
   ],
   "source": [
    "df_test= pd.DataFrame()\n",
    "\n",
    "df_test[\"t\"] = y_train\n",
    "df_test[\"sqd\"] = -x_train.sum(axis=-1)\n",
    "\n",
    "df_test.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7719858648235562, 1.8016361057569245e-285)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.4 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr as prs\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "y_lr_pred = reg.predict(x_val)\n",
    "prs(y_lr_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 488 µs\n"
     ]
    }
   ],
   "source": [
    "epochs= 1000\n",
    "neurons = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Lambda, Input, Reshape, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.constraints import non_neg\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    ann_pred = Sequential()\n",
    "    ann_pred.add(Dense(units=neurons, input_dim = x_train.shape[1]))\n",
    "    ann_pred.add(BatchNormalization())\n",
    "    ann_pred.add(Activation('relu'))\n",
    "    ann_pred.add(Dropout(0.5))\n",
    "\n",
    "    ann_pred.add(Dense(units=neurons))\n",
    "    ann_pred.add(BatchNormalization())\n",
    "    ann_pred.add(Activation('relu'))\n",
    "    ann_pred.add(Dropout(0.5))\n",
    "\n",
    "    ann_pred.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    opt = optimizers.Adagrad(lr=0.001)\n",
    "    \n",
    "    ann_pred.compile(loss='binary_crossentropy',optimizer=opt, metrics=['binary_crossentropy'])\n",
    "    return ann_pred\n",
    "\n",
    "ann = get_model()\n",
    "\n",
    "mon = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto') #val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.82 s, sys: 786 ms, total: 8.61 s\n",
      "Wall time: 6.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b68683b70>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ann.fit(x=x_train, y=y_train,epochs=epochs, validation_data=(x_val, y_val), callbacks=[mon], batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "y_ann_pred = ann.predict(x_val, batch_size=128).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7582680257227848, 1.231366100178887e-269)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.28 ms\n"
     ]
    }
   ],
   "source": [
    "prs(y_ann_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-8\n",
    "\n",
    "def elu1p(x):\n",
    "    return (K.elu(x) + 1)+epsilon\n",
    "\n",
    "inputs = Input(shape=(x_train.shape[1],))\n",
    "\n",
    "weighted_input=False\n",
    "sigma_regularizer= 1e-2 #Eta\n",
    "weight_sparsity = 1e-2 #Gamma\n",
    "\n",
    "numerator = Dense(1, use_bias=False, weights=[np.ones(x_train.shape[1]).reshape(-1,1)],\n",
    "                  trainable=weighted_input, \n",
    "                  #kernel_constraint=non_neg(), \n",
    "                  #kernel_regularizer=regularizers.l1(weight_sparsity), \n",
    "                  name=\"numerator\")(inputs)\n",
    "\n",
    "h1 = Dense(neurons)(inputs) \n",
    "h1act = Activation(\"relu\")(h1)\n",
    "\n",
    "sigma = Dense(1, activation=elu1p, name=\"sigma\")(h1act)\n",
    "\n",
    "denominator = Lambda(lambda x: (2*(x ** 2))**-1)(sigma)\n",
    "div = Multiply()([numerator, denominator])\n",
    "\n",
    "out = Lambda(lambda x: K.exp(x*-1))(div)\n",
    "\n",
    "rbfo_pred = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "opt = optimizers.Adagrad(lr=0.001)\n",
    "\n",
    "#opt = optimizers.RMSprop(lr=0.001, rho=0.9, decay=0.0, clipvalue=0.5)\n",
    "\n",
    "rbfo_pred.compile(loss=['binary_crossentropy'],optimizer=opt,metrics=['binary_crossentropy'])\n",
    "\n",
    "#rbfo_sigma = Model(inputs=rbfo_pred.input, outputs=rbfo_pred.get_layer(\"sigma\").output)\n",
    "\n",
    "#mon = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto') #val_acc\n",
    "\n",
    "#if weighted_input:\n",
    "#    rbfo_name = \"rbfo_pred_\"+str(x_train.shape[1])+\"_\"+str(sigma_regularizer)+\"sig_\"+str(weight_sparsity)+\"_wg.h5\"\n",
    "#else:\n",
    "#    rbfo_name = \"rbfo_pred_\"+str(x_train.shape[1])+\"_\"+str(sigma_regularizer)+\"sig.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.56 s, sys: 456 ms, total: 5.01 s\n",
      "Wall time: 3.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b627c9ef0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rbfo_pred.fit(x=x_train, y=y_train,epochs=epochs, validation_data=(x_val, y_val), callbacks=[mon], batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7628704359711005, 7.905953869296321e-275)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 56.1 ms\n"
     ]
    }
   ],
   "source": [
    "y_rbfo_pred = rbfo_pred.predict(x_val, batch_size=128).reshape(-1,)\n",
    "prs(y_rbfo_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
