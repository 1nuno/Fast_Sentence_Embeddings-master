{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverborchers/anaconda3/envs/fsedev/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "from fse.models import Average\n",
    "from fse.models.average import train_average_np\n",
    "from fse.models.average_inner import train_average_cy\n",
    "\n",
    "from fse import IndexedList\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim.downloader as api\n",
    "data = api.load(\"quora-duplicate-questions\")\n",
    "\n",
    "sentences = []\n",
    "for d in data:\n",
    "    sentences.append(d[\"question1\"])\n",
    "s = IndexedList(sentences[:500])\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors, FastTextKeyedVectors\n",
    "\n",
    "w2v = Word2VecKeyedVectors.load(\"/Volumes/Ext_HDD/Models/Static/google_news.model\", mmap=\"r\")\n",
    "ft = FastTextKeyedVectors.load(\"/Volumes/Ext_HDD/Models/Static/ft_crawl_300d_2m.model\", mmap=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test W2V Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if the fast version is available, you need to import the variable FAST_VERSION from fse.models.average. \n",
    "1 : The cython version is available\n",
    "-1 : The cython version is not available.\n",
    "\n",
    "If the cython compiliation fails, you will be notified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse.models.average import FAST_VERSION\n",
    "FAST_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.53 ms ± 24.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "w2v_avg = Average(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 s ± 8.02 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "w2v_avg = Average(w2v, lang_freq=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slowest part during the init is the induction of frequencies for words, as some pre-trained embeddings do not come with frequencies for words. This is only necessary for the SIF and uSIF Model, not for the Average model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_avg = Average(w2v)\n",
    "statistics = w2v_avg.scan_sentences(s)\n",
    "w2v_avg.prep.prepare_vectors(sv=w2v_avg.sv, total_sentences=statistics[\"max_index\"], update=False)\n",
    "memory = w2v_avg._get_thread_working_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9 ms ± 960 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_average_np(model=w2v_avg, indexed_sentences=s, target=w2v_avg.sv.vectors, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4 ms ± 52.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_average_cy(model=w2v_avg, indexed_sentences=s, target=w2v_avg.sv.vectors, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 500 sentences, the Cython version is about 7.15x faster than the numpy version when using a Word2Vec type model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_w2v_np = np.zeros_like(w2v_avg.sv.vectors)\n",
    "out_w2v_cy = np.zeros_like(w2v_avg.sv.vectors)\n",
    "train_average_np(model=w2v_avg, indexed_sentences=s, target=out_w2v_np, memory=w2v_avg._get_thread_working_mem())\n",
    "train_average_cy(model=w2v_avg, indexed_sentences=s, target=out_w2v_cy, memory=w2v_avg._get_thread_working_mem())\n",
    "\n",
    "np.allclose(out_w2v_np, out_w2v_cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test FastTextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_avg = Average(ft)\n",
    "statistics = ft_avg.scan_sentences(s)\n",
    "ft_avg.prep.prepare_vectors(sv=ft_avg.sv, total_sentences=statistics[\"max_index\"], update=False)\n",
    "memory = ft_avg._get_thread_working_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.6 ms ± 1.39 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_average_np(model=ft_avg, indexed_sentences=s, target=ft_avg.sv.vectors, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2 ms ± 52.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_average_cy(model=ft_avg, indexed_sentences=s, target=ft_avg.sv.vectors, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a FastText type model, the cython routine is about 10 times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ft_np = np.zeros_like(ft_avg.sv.vectors)\n",
    "out_ft_cy = np.zeros_like(ft_avg.sv.vectors)\n",
    "train_average_np(model=ft_avg, indexed_sentences=s, target=out_ft_np, memory=ft_avg._get_thread_working_mem())\n",
    "train_average_cy(model=ft_avg, indexed_sentences=s, target=out_ft_cy, memory=ft_avg._get_thread_working_mem())\n",
    "\n",
    "np.allclose(out_ft_np, out_ft_cy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
