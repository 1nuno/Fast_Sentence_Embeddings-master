{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fse - Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to fse - fast sentence embeddings. The library is intended to compute sentence embeddings as fast as possible. \n",
    "It offers a simple and easy to understand syntax for you to use in your own projects. Before we start with any model, lets have a look at the input types which.\n",
    "All fse models require an iterable/generator which produces an IndexedSentence object. An IndexedSentence is a named tuple with two fields: words and index. The index is required for the multi-core processing, as sentences might not be processed sequentially. The index dictates, which row of the corresponding sentence vector matrix the sentence belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:25:06,307 : MainThread : DEBUG : {'uri': '/Users/oliverborchers/anaconda3/envs/fsedev/lib/python3.7/site-packages/smart_open/VERSION', 'mode': 'r', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2019-09-02 17:25:06,741 : MainThread : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'world']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from fse import IndexedSentence\n",
    "from fse import IndexedList\n",
    "s = IndexedSentence([\"Hello\", \"world\"], 0)\n",
    "print(s.words)\n",
    "print(s.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words of the IndexedSentence will always consist of a list of strings. Otherwise the train method will raise an Error. However, most input data is available as a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_a = [\"Hello there\", \"how are you?\"]\n",
    "sentences_b = [\"today is a good day\", \"Lorem ipsum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with this common input format, fse provides the IndexedList, which handels all required data operations for you. You can provide multiple lists (or sets) which will all be merged into a single list. This eases work if you have to work with the STS datasets. IndexedList will perform an automatic split if you don't provide a specific function for the model to split on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IndexedSentence(words=['Hello', 'there'], index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = IndexedList(sentences_a, sentences_b)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save memory, we do not convert the original lists inplace. The conversion will only take place once you call the getitem method. To access the original data, call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello there', 'how are you?', 'today is a good day', 'Lorem ipsum']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is already preprocessed as a list of lists you can provide the argument pre_splitted=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IndexedSentence(words=['Hello', 'there'], index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_splitted = [\"Hello there\".split(), \"how are you?\".split()]\n",
    "s = IndexedList(sentences_splitted, pre_splitted=True)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to provide your own splitting function, you can pass a callable to the split_func argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IndexedSentence(words=['Hello', 'there'], index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_func(string):\n",
    "    return string.split()\n",
    "\n",
    "s = IndexedList(sentences_a, split=False, split_func=split_func)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to stream a file from disk (where each line corresponds to a sentence) you can use the IndexedLineDocument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:25:12,687 : MainThread : DEBUG : {'uri': PosixPath('../fse/test/test_data/test_sentences.txt'), 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    }
   ],
   "source": [
    "from fse import IndexedLineDocument\n",
    "doc = IndexedLineDocument(\"../fse/test/test_data/test_sentences.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:25:16,545 : MainThread : DEBUG : {'uri': PosixPath('../fse/test/test_data/test_sentences.txt'), 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t['Good', 'stuff', 'i', 'just', 'wish', 'it', 'lasted', 'longer']\n",
      "1\t['Hp', 'makes', 'qualilty', 'stuff']\n",
      "2\t['I', 'like', 'it']\n",
      "3\t['Try', 'it', 'you', 'will', 'like', 'it']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for s in doc:\n",
    "    print(f\"{s.index}\\t{s.words}\")\n",
    "    i += 1\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are later working with the similarity of sentences, the IndexedLineDocument provides you the option to access each line by its corresponding index. This helps you in determining the similarity of sentences, as the most_similar method would otherwise just return indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:25:17,428 : MainThread : DEBUG : {'uri': PosixPath('../fse/test/test_data/test_sentences.txt'), 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I feel like i just got screwed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model / Performing inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a fse model is simple. You only need a pre-trained word embedding model which you use during the initializiation of the fse model you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:25:20,478 : MainThread : INFO : loading projection weights from /Users/oliverborchers/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n",
      "2019-09-02 17:25:20,480 : MainThread : DEBUG : {'uri': '/Users/oliverborchers/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2019-09-02 17:26:08,015 : MainThread : INFO : loaded (400000, 100) matrix from /Users/oliverborchers/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "data = api.load(\"quora-duplicate-questions\")\n",
    "glove = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverborchers/anaconda3/envs/fsedev/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-09-02 17:26:16,621 : MainThread : DEBUG : {'uri': '/Users/oliverborchers/gensim-data/quora-duplicate-questions/quora-duplicate-questions.gz', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': {}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468640\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for d in data:\n",
    "    # Let's blow up the data a bit by replicating each sentence.\n",
    "    for i in range(4):\n",
    "        sentences.append(d[\"question1\"])\n",
    "        sentences.append(d[\"question2\"])\n",
    "s = IndexedList(sentences)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have about 3234320 sentences we want to compute the embeddings for. If you import the FAST_VERSION variable as follows you can ensure, that the compiliation of the cython routines worked correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse.models.average import FAST_VERSION\n",
    "FAST_VERSION\n",
    "# 1 -> The fast version works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fse.models import Average\n",
    "model = Average(glove, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:26:43,709 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2019-09-02 17:26:48,710 : MainThread : INFO : SCANNING : finished 1059350 sentences with 11700688 words\n",
      "2019-09-02 17:26:53,710 : MainThread : INFO : SCANNING : finished 2160826 sentences with 23865035 words\n",
      "2019-09-02 17:26:58,710 : MainThread : INFO : SCANNING : finished 3298528 sentences with 36461432 words\n",
      "2019-09-02 17:27:03,710 : MainThread : INFO : SCANNING : finished 4407256 sentences with 48744308 words\n",
      "2019-09-02 17:27:08,710 : MainThread : INFO : SCANNING : finished 5545789 sentences with 61305355 words\n",
      "2019-09-02 17:27:12,737 : MainThread : WARNING : found 16 empty sentences\n",
      "2019-09-02 17:27:12,738 : MainThread : INFO : finished scanning 6468640 sentences with an average length of 11 and 71556728 total words\n",
      "2019-09-02 17:27:12,933 : MainThread : INFO : estimated memory for 6468640 sentences with 100 dimensions and 400000 vocabulary: 2621 MB (2 GB)\n",
      "2019-09-02 17:27:12,934 : MainThread : INFO : initializing sentence vectors for 6468640 sentences\n",
      "2019-09-02 17:27:24,051 : MainThread : INFO : begin training\n",
      "2019-09-02 17:27:29,177 : MainThread : INFO : PROGRESS : finished 12.46% with 805734 sentences and 6123719 words, 161146 sentences/s\n",
      "2019-09-02 17:27:34,181 : MainThread : INFO : PROGRESS : finished 25.69% with 1662084 sentences and 12634712 words, 171270 sentences/s\n",
      "2019-09-02 17:27:39,183 : MainThread : INFO : PROGRESS : finished 38.15% with 2467867 sentences and 18768108 words, 161156 sentences/s\n",
      "2019-09-02 17:27:44,185 : MainThread : INFO : PROGRESS : finished 50.85% with 3289537 sentences and 25030499 words, 164334 sentences/s\n",
      "2019-09-02 17:27:49,188 : MainThread : INFO : PROGRESS : finished 63.58% with 4112981 sentences and 31298682 words, 164688 sentences/s\n",
      "2019-09-02 17:27:54,191 : MainThread : INFO : PROGRESS : finished 74.86% with 4842250 sentences and 36852786 words, 145853 sentences/s\n",
      "2019-09-02 17:27:59,191 : MainThread : INFO : PROGRESS : finished 86.81% with 5615553 sentences and 42729635 words, 154660 sentences/s\n",
      "2019-09-02 17:28:04,192 : MainThread : INFO : PROGRESS : finished 98.91% with 6398256 sentences and 48718280 words, 156540 sentences/s\n",
      "2019-09-02 17:28:04,677 : Thread-5 : DEBUG : job loop exiting, total 7161 jobs\n",
      "2019-09-02 17:28:04,679 : Thread-4 : DEBUG : worker exiting, processed 7161 jobs\n",
      "2019-09-02 17:28:04,680 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-02 17:28:04,682 : MainThread : INFO : training on 6468624 effective sentences with 49255184 effective words took 40s with 159205 sentences/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6468624, 49255184)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model runs at around 160,000 sentences / seconds. That means we finish the task in 6 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the sif model is trained, you can perform additional inferences for unknown sentences. This two step process for new data is required, as computing the principal components for models like SIF and uSIF will require a fair amount of sentences. If you want the vector for a single sentence (which is out of the training vocab), just use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:28:21,743 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2019-09-02 17:28:21,745 : MainThread : INFO : finished scanning 1 sentences with an average length of 3 and 3 total words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.26518148,  0.026005  ,  0.418165  , -0.491575  , -0.4111695 ,\n",
       "         0.75515497, -0.26521   ,  0.2275845 , -0.0826425 , -0.15927498,\n",
       "         0.17639194,  0.132565  ,  0.46823   ,  0.26481998, -0.17778   ,\n",
       "        -0.529775  , -0.04180501,  0.07661   , -0.59272003,  0.613505  ,\n",
       "        -0.153675  ,  0.419775  , -0.16156301, -0.15667   ,  0.3594    ,\n",
       "         0.4279275 , -0.524735  , -0.73454   ,  0.81944   ,  0.01679499,\n",
       "         0.38288   ,  0.875635  ,  0.68189   ,  0.17048   , -0.19861001,\n",
       "         0.562425  , -0.13079502,  0.300335  ,  0.42567   , -0.41034502,\n",
       "        -0.168975  , -0.00744   ,  0.624575  , -0.54095   , -0.45428002,\n",
       "        -0.082555  , -0.503395  ,  0.07380998,  0.41128498, -0.93290997,\n",
       "        -0.12029   , -0.16773999,  0.113726  ,  0.938125  , -0.0205    ,\n",
       "        -2.2649999 ,  0.3064845 ,  0.17881   ,  1.257695  ,  0.322062  ,\n",
       "         0.3309515 ,  1.6305    , -0.26051632, -0.17654894,  0.63209003,\n",
       "         0.11346   ,  0.72634   ,  0.35617   ,  0.271445  , -0.2048    ,\n",
       "        -0.086955  ,  0.40915552,  0.4176175 , -0.97046995, -0.088185  ,\n",
       "         0.80659497,  0.156185  , -0.418625  , -0.50085497,  0.083742  ,\n",
       "         0.19953   ,  0.65332997,  0.15279001, -0.26908   , -1.76225   ,\n",
       "        -0.279055  , -0.44348502, -0.01228501, -0.62225497, -0.355313  ,\n",
       "        -0.304465  ,  0.23094499,  1.01325   ,  0.141     , -0.755485  ,\n",
       "        -0.36988   , -0.436015  , -0.09997   ,  0.2612    ,  0.76803005]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = IndexedSentence(\"Hello my friends\".split(), 0)\n",
    "model.infer([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to query the model or perform similarity computations we can just access the model.sv (sentence vectors) object and use its method. To get a vector for an index, just call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9212671e-02,  5.5341166e-02,  3.0522481e-01,  1.0868758e-01,\n",
       "        2.0464543e-01, -6.3812248e-02, -2.9070374e-01,  4.0029332e-02,\n",
       "       -1.5944116e-01,  1.9179760e-02, -4.7995415e-02, -4.4555258e-02,\n",
       "        1.2083842e-01, -1.5988165e-01, -9.1990761e-02, -1.7833400e-01,\n",
       "        1.9876814e-01,  7.4273467e-02, -2.3242335e-01,  1.5821201e-01,\n",
       "        2.5478417e-01, -3.5725668e-02,  1.6262001e-01,  2.9798460e-01,\n",
       "        8.6748540e-02, -1.6531321e-01,  4.8800584e-02, -3.4739166e-01,\n",
       "       -4.4252168e-02, -8.5781654e-03, -2.6755494e-01,  4.6747109e-01,\n",
       "       -1.0570883e-01, -4.8522335e-02,  6.5135837e-02,  3.6621445e-01,\n",
       "        1.7579168e-01,  1.9990325e-01, -1.2957168e-01, -3.0050886e-01,\n",
       "       -3.6363500e-01, -2.3632818e-01,  1.4003392e-03, -3.1585187e-01,\n",
       "       -1.7299536e-01,  9.5002741e-02,  1.1902635e-01, -2.7074313e-01,\n",
       "       -1.7854732e-01, -9.2564583e-01, -1.7807779e-01, -2.0552608e-03,\n",
       "        2.2348361e-01,  1.1666777e+00, -3.9630362e-01, -2.5325801e+00,\n",
       "       -2.2108541e-01, -3.8677084e-01,  1.8828082e+00,  2.2949016e-01,\n",
       "       -1.8164276e-01,  4.5904994e-01, -2.4908309e-01,  1.8163082e-01,\n",
       "        6.7344809e-01,  1.3692242e-01,  1.9691375e-01,  3.4175587e-01,\n",
       "        3.3226264e-01, -1.8786511e-01, -4.1189133e-03, -2.8621644e-01,\n",
       "       -3.8661084e-01, -4.7933254e-01,  3.2539587e-02, -8.4838659e-02,\n",
       "       -2.3467050e-01,  1.7754784e-03, -8.1421202e-01, -1.1635710e-01,\n",
       "        5.8705914e-01,  2.5857052e-01, -4.6982083e-01,  1.3541442e-01,\n",
       "       -1.0181496e+00, -1.4735118e-01,  8.4438324e-02, -2.3570304e-01,\n",
       "       -1.0781509e-01, -3.5354596e-01, -1.9062562e-02, -2.6595157e-02,\n",
       "       -1.8769139e-01,  7.6033324e-03, -5.2978265e-01,  1.3016926e-01,\n",
       "        1.0108001e-02, -4.3044385e-01,  5.9856331e-01,  1.7814907e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the similarity or distance between two sentence from the training set you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993\n",
      "0.007\n"
     ]
    }
   ],
   "source": [
    "print(model.sv.similarity(0,1).round(3))\n",
    "print(model.sv.distance(0,1).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further call for the most similar sentences given an index. For example, we want to know the most similar sentences for sentence index 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexedSentence(['Should', 'I', 'buy', 'tiago?'], 100)\n"
     ]
    }
   ],
   "source": [
    "print(s[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:28:25,437 : MainThread : INFO : precomputing L2-norms of sentence vectors\n",
      "/Users/oliverborchers/Library/Mobile Documents/com~apple~CloudDocs/Diss/Medium/gensim-develop/gensim/models/keyedvectors.py:2377: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n",
      "/Users/oliverborchers/Library/Mobile Documents/com~apple~CloudDocs/Diss/Medium/gensim-develop/gensim/models/keyedvectors.py:2377: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(754564, 1.0),\n",
       " (754562, 1.0),\n",
       " (1836814, 1.0),\n",
       " (1836815, 1.0),\n",
       " (754574, 1.0),\n",
       " (754572, 1.0),\n",
       " (754570, 1.0),\n",
       " (754568, 1.0),\n",
       " (754566, 1.0),\n",
       " (1836812, 1.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.most_similar(100)\n",
    "# Division by zero can happen if you encounter empy sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the preceding function will only supply the indices of the most similar sentences. You can circumvent this problem by passing an indexable function to the most_similar call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Should Google buy Twitter?', 754564, 1.0),\n",
       " ('Should Google buy Twitter?', 754562, 1.0),\n",
       " (\"Why doesn't Google buy Quora?\", 1836814, 1.0),\n",
       " (\"Why doesn't Facebook buy Quora?\", 1836815, 1.0),\n",
       " ('Should Google buy Twitter?', 754574, 1.0),\n",
       " ('Should Google buy Twitter?', 754572, 1.0),\n",
       " ('Should Google buy Twitter?', 754570, 1.0),\n",
       " ('Should Google buy Twitter?', 754568, 1.0),\n",
       " ('Should Google buy Twitter?', 754566, 1.0),\n",
       " (\"Why doesn't Google buy Quora?\", 1836812, 1.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.most_similar(100, indexable=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go. This is a lot more understandable than the initial list of indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for sentences, which are similar to a given word vector, you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How do I make easy money?', 842126, 0.8764350414276123),\n",
       " ('How do I make easy money?', 5387888, 0.8764350414276123),\n",
       " ('How do I make easy money?', 2113542, 0.8764350414276123),\n",
       " ('How do I make easy money?', 2113540, 0.8764350414276123),\n",
       " ('How do I make easy money?', 2113538, 0.8764350414276123),\n",
       " ('How do I make easy money?', 2113536, 0.8764350414276123),\n",
       " ('How do I make easy money?', 842124, 0.8764350414276123),\n",
       " ('How do I make easy money?', 2113546, 0.8764350414276123),\n",
       " ('How do I make easy money?', 5387894, 0.8764350414276123),\n",
       " ('How do I make easy money?', 5387896, 0.8764350414276123)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.similar_by_word(\"easy\", wv=glove, indexable=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you can query for unknown (or new) sentences by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-02 17:28:46,689 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2019-09-02 17:28:46,691 : MainThread : INFO : finished scanning 1 sentences with an average length of 6 and 6 total words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Is it easy to learn Hebrew if you learn Arabic?',\n",
       "  4666697,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Arabic if you learn Hebrew first?',\n",
       "  4666696,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Arabic if you learn Hebrew first?',\n",
       "  4666702,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Hebrew if you learn Arabic?',\n",
       "  4666701,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Arabic if you learn Hebrew first?',\n",
       "  4666700,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Hebrew if you learn Arabic?',\n",
       "  4666699,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Arabic if you learn Hebrew first?',\n",
       "  4666698,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Hebrew if you learn Arabic?',\n",
       "  4666691,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Arabic if you learn Hebrew first?',\n",
       "  4666690,\n",
       "  0.9844098091125488),\n",
       " ('Is it easy to learn Hebrew if you learn Arabic?',\n",
       "  4666695,\n",
       "  0.9844098091125488)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.similar_by_sentence(\"Is this really easy to learn\".split(), model=model, indexable=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to browse through the library and get to know the functions a little better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
