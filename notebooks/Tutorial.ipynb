{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fse - Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to fse - fast sentence embeddings. The library is intended to compute sentence embeddings as fast as possible. \n",
    "It offers a simple and easy to understand syntax for you to use in your own projects. Before we start with any model, lets have a look at the input types which.\n",
    "All fse models require an iterable/generator which produces an IndexedSentence object. An IndexedSentence is a named tuple with two fields: words and index. The index is required for the multi-core processing, as sentences might not be processed sequentially. The index dictates, which row of the corresponding sentence vector matrix the sentence belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 16:47:39,738 : MainThread : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'world']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from fse import IndexedSentence\n",
    "s = IndexedSentence([\"Hello\", \"world\"], 0)\n",
    "print(s.words)\n",
    "print(s.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words of the IndexedSentence will always consist of a list of strings. Otherwise the train method will raise an Error. However, most input data is available as a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_a = [\"Hello there\", \"how are you?\"]\n",
    "sentences_b = [\"today is a good day\", \"Lorem ipsum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with this common input format, fse provides the IndexedList, which handels all required data operations for you. You can provide multiple lists (or sets) which will all be merged into a single list. This eases work if you have to work with the STS datasets. IndexedList will perform an automatic split if you don't provide a specific function for the model to split on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IndexedSentence(words=['Hello', 'there'], index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse import IndexedList\n",
    "s = IndexedList(sentences_a, sentences_b)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save memory, we do not convert the original lists inplace. The conversion will only take place once you call the getitem method. To access the original data, call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello there', 'how are you?', 'today is a good day', 'Lorem ipsum']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is already preprocessed as a list of lists you can provide the argument pre_splitted=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IndexedSentence(words=['Hello', 'there'], index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_splitted = [\"Hello there\".split(), \"how are you?\".split()]\n",
    "s = IndexedList(sentences_splitted, pre_splitted=True)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to provide your own splitting function, you can pass a callable to the split_func argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IndexedSentence(words=['Hello', 'there'], index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_func(string):\n",
    "    return string.split()\n",
    "\n",
    "s = IndexedList(sentences_a, split=False, split_func=split_func)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to stream a file from disk (where each line corresponds to a sentence) you can use the IndexedLineDocument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fse import IndexedLineDocument\n",
    "doc = IndexedLineDocument(\"../test/test_data/test_sentences.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t['Good', 'stuff', 'i', 'just', 'wish', 'it', 'lasted', 'longer']\n",
      "1\t['Hp', 'makes', 'qualilty', 'stuff']\n",
      "2\t['I', 'like', 'it']\n",
      "3\t['Try', 'it', 'you', 'will', 'like', 'it']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for s in doc:\n",
    "    print(f\"{s.index}\\t{s.words}\")\n",
    "    i += 1\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are later working with the similarity of sentences, the IndexedLineDocument provides you the option to access each line by its corresponding index. This helps you in determining the similarity of sentences, as the most_similar method would otherwise just return indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I feel like i just got screwed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model / Performing inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a fse model is simple. You only need a pre-trained word embedding model which you use during the initializiation of the fse model you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 16:47:40,935 : MainThread : INFO : loading projection weights from /Users/oliverborchers/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n",
      "2019-08-25 16:48:25,069 : MainThread : INFO : loaded (400000, 100) matrix from /Users/oliverborchers/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "data = api.load(\"quora-duplicate-questions\")\n",
    "glove = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverborchers/anaconda3/envs/fsedev/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3234320\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for d in data:\n",
    "    # Let's blow up the data a bit by replicating each sentence.\n",
    "    for i in range(4):\n",
    "        sentences.append(d[\"question1\"])\n",
    "        sentences.append(d[\"question2\"])\n",
    "s = IndexedList(sentences)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have about 3234320 sentences we want to compute the embeddings for. If you import the FAST_VERSION variable as follows you can ensure, that the compiliation of the cython routines worked correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse.models.average import FAST_VERSION\n",
    "FAST_VERSION\n",
    "# 1 -> The fast version works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 16:48:29,876 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    }
   ],
   "source": [
    "from fse.models import SIF\n",
    "model = SIF(glove, lang_freq=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 16:48:30,446 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2019-08-25 16:48:35,446 : MainThread : INFO : SCANNING : finished 1053801 sentences with 11639639 words\n",
      "2019-08-25 16:48:40,446 : MainThread : INFO : SCANNING : finished 1922223 sentences with 21245025 words\n",
      "2019-08-25 16:48:45,446 : MainThread : INFO : SCANNING : finished 2921544 sentences with 32296684 words\n",
      "2019-08-25 16:48:46,877 : MainThread : WARNING : found 8 empty sentences\n",
      "2019-08-25 16:48:46,877 : MainThread : INFO : finished scanning 3234320 sentences with an average length of 11 and 35778364 total words\n",
      "2019-08-25 16:48:47,000 : MainThread : INFO : estimated memory for 3234320 sentences with 100 dimensions and 400000 vocabulary: 1387 MB (1 GB)\n",
      "2019-08-25 16:48:47,001 : MainThread : INFO : initializing sentence vectors for 3234320 sentences\n",
      "2019-08-25 16:48:52,168 : MainThread : INFO : pre-computing SIF weights for 400000 words\n",
      "2019-08-25 16:48:52,410 : MainThread : INFO : begin training\n",
      "2019-08-25 16:48:57,429 : MainThread : INFO : PROGRESS : finished 23.35% with 755069 sentences and 5740552 words, 151013 sentences/s\n",
      "2019-08-25 16:49:02,432 : MainThread : INFO : PROGRESS : finished 44.93% with 1453209 sentences and 11062137 words, 139628 sentences/s\n",
      "2019-08-25 16:49:07,437 : MainThread : INFO : PROGRESS : finished 66.57% with 2153039 sentences and 16392967 words, 139966 sentences/s\n",
      "2019-08-25 16:49:12,439 : MainThread : INFO : PROGRESS : finished 90.42% with 2924478 sentences and 22252626 words, 154287 sentences/s\n",
      "2019-08-25 16:49:14,445 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-25 16:49:22,409 : MainThread : INFO : computing 1 principal components took 7s\n",
      "2019-08-25 16:49:23,566 : MainThread : INFO : removing 1 principal components took 1s\n",
      "2019-08-25 16:49:23,566 : MainThread : INFO : training on 3234312 effective sentences with 24627592 effective words took 22s with 146779 sentences/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3234312, 24627592)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model runs at around 140,000 sentences / seconds. That means we finish the task in 6 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the sif model is trained, you can perform additional inferences for unknown sentences. This two step process for new data is required, as computing the principal components for models like SIF and uSIF will require a fair amount of sentences. If you want the vector for a single sentence (which is out of the training vocab), just use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 16:49:23,574 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2019-08-25 16:49:23,575 : MainThread : INFO : finished scanning 1 sentences with an average length of 3 and 3 total words\n",
      "2019-08-25 16:49:23,576 : MainThread : INFO : removing 1 principal components took 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.21351576, -0.09288862, -0.0119403 , -0.1889258 , -0.06775595,\n",
       "         0.35332185, -0.05645356,  0.0137386 , -0.05183255, -0.23596533,\n",
       "        -0.00128163, -0.02317927,  0.12560129,  0.12072462, -0.11241709,\n",
       "        -0.19177678,  0.01603449, -0.1464626 , -0.23061372,  0.2182611 ,\n",
       "        -0.12705329,  0.22893776, -0.0711069 , -0.11446346,  0.09433743,\n",
       "         0.12357411, -0.1769016 ,  0.00240368,  0.37974662,  0.11471796,\n",
       "         0.22353241,  0.15717354,  0.35247564,  0.11246662, -0.05959256,\n",
       "         0.1634959 ,  0.12703045,  0.03458374,  0.23784837, -0.09175231,\n",
       "        -0.02836828,  0.13040201,  0.21949698, -0.04487759, -0.09548192,\n",
       "        -0.07434461, -0.35468528,  0.2915059 ,  0.33256316,  0.02439231,\n",
       "        -0.10745892, -0.14252488,  0.05496336, -0.05148613,  0.07837424,\n",
       "        -0.00869656,  0.02335814,  0.06826252, -0.3131165 ,  0.06759262,\n",
       "         0.11155459,  0.41700476,  0.06062685, -0.12836376, -0.08194584,\n",
       "        -0.06413196,  0.14149769,  0.15394527,  0.14578202,  0.02532689,\n",
       "        -0.12522505,  0.1918849 ,  0.08518   , -0.3720084 , -0.19226463,\n",
       "         0.3418705 ,  0.26025438, -0.17308585,  0.07716222,  0.07830147,\n",
       "        -0.14177874,  0.37215713,  0.36934143, -0.18599685, -0.19103587,\n",
       "        -0.06847534, -0.30356   ,  0.11574819, -0.20183076, -0.14519393,\n",
       "        -0.06176683,  0.08282184,  0.49341515,  0.02979594, -0.23668444,\n",
       "        -0.13155949, -0.15727358,  0.17416319, -0.14990012,  0.21662608]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = IndexedSentence(\"Hello my friends\".split(), 0)\n",
    "model.infer([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to query the model or perform similarity computations we can just access the model.sv (sentence vectors) object and use its method. To get a vector for an index, just call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05602818, -0.05382837, -0.02521911,  0.21895382,  0.12569104,\n",
       "       -0.23286618, -0.1197442 , -0.09862348, -0.00718871, -0.05476034,\n",
       "       -0.04207896,  0.06721796, -0.07115522, -0.17658317, -0.11463246,\n",
       "        0.01588205, -0.04609087,  0.00192668,  0.06665533,  0.01994948,\n",
       "        0.03874935,  0.01709431, -0.13803758,  0.11546692, -0.08431192,\n",
       "        0.01444703,  0.05757499,  0.10997273, -0.06485826,  0.03536717,\n",
       "       -0.12626679,  0.04387207, -0.05193089, -0.04863958,  0.06036283,\n",
       "        0.04478271,  0.15353824, -0.09030947, -0.05488757, -0.11358316,\n",
       "        0.01325982, -0.03299464,  0.02760698,  0.00774282, -0.11196408,\n",
       "        0.08852603, -0.15662912,  0.07745412, -0.02901547, -0.1876617 ,\n",
       "       -0.14219847,  0.00209911, -0.01960241,  0.05305627, -0.10361422,\n",
       "       -0.05813611, -0.11573686, -0.00658958,  0.21034062, -0.10365039,\n",
       "        0.04388143, -0.23539278, -0.04639078,  0.02537311, -0.08185716,\n",
       "        0.06672949, -0.18605871,  0.08167145,  0.07045798, -0.00467298,\n",
       "        0.0327092 ,  0.00373585, -0.16041704, -0.1436666 , -0.10682634,\n",
       "       -0.1152529 , -0.10109591,  0.06043637,  0.01189947, -0.10992781,\n",
       "        0.05652052,  0.15081438,  0.02532822, -0.04087038,  0.19580597,\n",
       "       -0.01759166,  0.02058122, -0.06597687,  0.01145387, -0.03310017,\n",
       "        0.00841566,  0.03367271, -0.01495149, -0.14850685, -0.09221204,\n",
       "        0.07743885,  0.1767587 , -0.09100661,  0.02711007,  0.12564386],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the similarity or distance between two sentence from the training set you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939\n",
      "0.061\n"
     ]
    }
   ],
   "source": [
    "print(model.sv.similarity(0,1).round(3))\n",
    "print(model.sv.distance(0,1).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further call for the most similar sentences given an index. For example, we want to know the most similar sentences for sentence index 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexedSentence(['What', 'can', 'make', 'Physics', 'easy', 'to', 'learn?'], 100)\n"
     ]
    }
   ],
   "source": [
    "print(s[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 16:49:23,609 : MainThread : INFO : precomputing L2-norms of sentence vectors\n",
      "/Users/oliverborchers/Library/Mobile Documents/com~apple~CloudDocs/Diss/Medium/gensim-develop/gensim/models/keyedvectors.py:2377: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n",
      "/Users/oliverborchers/Library/Mobile Documents/com~apple~CloudDocs/Diss/Medium/gensim-develop/gensim/models/keyedvectors.py:2377: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(102, 0.9999999403953552),\n",
       " (1920653, 0.9999999403953552),\n",
       " (1920655, 0.9999999403953552),\n",
       " (1920651, 0.9999999403953552),\n",
       " (1920649, 0.9999999403953552),\n",
       " (96, 0.9999999403953552),\n",
       " (98, 0.9999999403953552),\n",
       " (2752780, 0.969744086265564),\n",
       " (2752778, 0.969744086265564),\n",
       " (2752776, 0.969744086265564)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.most_similar(100)\n",
    "# Division by zero can happen if you encounter empy sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the preceding function will only supply the indices of the most similar sentences. You can circumvent this problem by passing an indexable function to the most_similar call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What can make Physics easy to learn?', 102, 0.9999999403953552),\n",
       " ('What can make Physics easy to learn?', 1920653, 0.9999999403953552),\n",
       " ('What can make Physics easy to learn?', 1920655, 0.9999999403953552),\n",
       " ('What can make Physics easy to learn?', 1920651, 0.9999999403953552),\n",
       " ('What can make Physics easy to learn?', 1920649, 0.9999999403953552),\n",
       " ('What can make Physics easy to learn?', 96, 0.9999999403953552),\n",
       " ('What can make Physics easy to learn?', 98, 0.9999999403953552),\n",
       " ('How can I make an easy Mrs. Peacock costume?', 2752780, 0.969744086265564),\n",
       " ('How can I make an easy Mrs. Peacock costume?', 2752778, 0.969744086265564),\n",
       " ('How can I make an easy Mrs. Peacock costume?', 2752776, 0.969744086265564)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.most_similar(100, indexable=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go. This is a lot more understandable than the initial list of indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for sentences, which are similar to a given word vector, you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Is Hadoop easy to learn?', 2607199, 0.6739339828491211),\n",
       " ('Is Hadoop easy to learn?', 2607195, 0.6739339828491211),\n",
       " ('Is Python easy to learn?', 58913, 0.6739339828491211),\n",
       " ('Is Python easy to learn?', 58915, 0.6739339828491211),\n",
       " ('Is Python easy to learn?', 58917, 0.6739339828491211),\n",
       " ('Is Python easy to learn?', 58919, 0.6739339828491211),\n",
       " ('Is Java easy to learn?', 2495013, 0.6739339828491211),\n",
       " ('Is Hadoop easy to learn?', 2607197, 0.6739339828491211),\n",
       " ('Is Adobe Premiere Pro easy to learn?', 712780, 0.6739339828491211),\n",
       " ('Is Adobe Premiere Pro easy to learn?', 712776, 0.6739339828491211)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.similar_by_word(\"easy\", wv=glove, indexable=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you can query for unknown (or new) sentences by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 16:49:25,864 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2019-08-25 16:49:25,865 : MainThread : INFO : finished scanning 1 sentences with an average length of 6 and 6 total words\n",
      "2019-08-25 16:49:25,866 : MainThread : INFO : removing 1 principal components took 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('How do I learn C# the easy way?', 1120173, 0.959309458732605),\n",
       " ('How do I learn C# the easy way?', 1120169, 0.959309458732605),\n",
       " ('How do I learn C# the easy way?', 1120171, 0.959309458732605),\n",
       " ('How do I learn C# the easy way?', 1120175, 0.959309458732605),\n",
       " ('How easy is it to learn Java?', 2894414, 0.9592858552932739),\n",
       " ('How easy is it to learn Java?', 176146, 0.9592858552932739),\n",
       " ('How easy is it to learn Java?', 176150, 0.9592858552932739),\n",
       " ('How easy is it to learn Java?', 121921, 0.9592858552932739),\n",
       " ('How easy is it to learn C?', 1552117, 0.9592858552932739),\n",
       " ('How easy is it to learn Java?', 176144, 0.9592858552932739)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.similar_by_sentence(\"Is this really easy to learn\".split(), model=model, indexable=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to browse through the library and get to know the functions a little better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
